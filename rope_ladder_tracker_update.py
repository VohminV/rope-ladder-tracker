#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Rope Ladder Tracker (–æ–¥–∏–Ω —Ñ–∞–π–ª).
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
 - –ø–æ—Ç–æ–∫–æ–≤—ã–π –∑–∞—Ö–≤–∞—Ç –∫–∞–¥—Ä–æ–≤
 - –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CLAHE –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
 - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è UMat/OpenCL –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (–µ—Å–ª–∏ OpenCV —Å–æ–±—Ä–∞–Ω)
 - RANSAC-–æ—Ü–µ–Ω–∫–∞ affine –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤
 - –ø—Ä–æ—Å—Ç–∞—è Kalman —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–æ–∂–µ–Ω–∏—è
"""

import cv2
import numpy as np
import time
import logging
import json
import os
import threading

# ----------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (–ø–æ–¥ Orange Pi 5) -----------------
IMAGE_WIDTH_PX = 640   # –º–æ–∂–Ω–æ —Å–Ω–∏–∑–∏—Ç—å –¥–æ 320 –¥–ª—è –±–æ–ª—å—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
IMAGE_HEIGHT_PX = 480
TARGET_FPS = 20        # realistic for ARM device; —Ä–µ–≥—É–ª–∏—Ä—É–π
FRAME_INTERVAL = 1.0 / TARGET_FPS

MIN_FEATURES = 20
MAX_FEATURES = 600
DISTANCE_THRESHOLD = 28.0
BACKTRACK_MARGIN = 14.0
HYSTERESIS_MARGIN = 10.0
LADDER_UPDATE_INTERVAL = 0.5
SMOOTHING_FACTOR = 0.75  # EMA –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞ (–¥–æ–ø. –∫ Kalman)
FLAG_PATH = 'tracking_enabled.flag'
OFFSETS_FILE = 'offsets.json'

# ROI: None –∏–ª–∏ (x,y,w,h) ‚Äî –µ—Å–ª–∏ –∑–Ω–∞–µ—à—å –æ–±–ª–∞—Å—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–∞, —É–∫–∞–∂–∏, —á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å
ROI = None  # e.g. (100,50,400,300)

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)-5s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("rope_ladder_improved.log", mode='w', encoding='utf-8')
    ]
)

# ----------------- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ offsets -----------------
def save_offset(dx_m, dy_m, angle=0.0):
    data = {
        'x': float(dx_m),
        'y': float(dy_m),
        'angle': float(angle)
    }
    tmp = OFFSETS_FILE + '.tmp'
    try:
        with open(tmp, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)
        os.replace(tmp, OFFSETS_FILE)
    except Exception as e:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å offsets: {e}")

# ----------------- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–ª–∞–≥–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ -----------------
def is_tracking_enabled():
    try:
        with open(FLAG_PATH, 'r') as f:
            return f.read().strip() == '1'
    except:
        return False

# ----------------- –ü–æ—Ç–æ–∫ –∑–∞—Ö–≤–∞—Ç–∞ –∫–∞–¥—Ä–æ–≤ -----------------
class FrameGrabber(threading.Thread):
    def __init__(self, src=0, width=IMAGE_WIDTH_PX, height=IMAGE_HEIGHT_PX, fps=TARGET_FPS):
        super().__init__(daemon=True)
        self.cap = cv2.VideoCapture(src)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        self.cap.set(cv2.CAP_PROP_FPS, fps)
        self.lock = threading.Lock()
        self.running = True
        self.latest_frame = None
        self._ready = threading.Event()

    def run(self):
        while self.running:
            ret, frame = self.cap.read()
            if not ret or frame is None:
                time.sleep(0.01)
                continue
            with self.lock:
                self.latest_frame = frame
                self._ready.set()
        self.cap.release()

    def read(self, timeout=1.0):
        # wait for a frame to be ready
        ok = self._ready.wait(timeout)
        if not ok:
            return False, None
        with self.lock:
            frame = None if self.latest_frame is None else self.latest_frame.copy()
            self._ready.clear()
        return frame is not None, frame

    def stop(self):
        self.running = False

# ----------------- –ü—Ä–æ—Å—Ç–æ–π Kalman —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞ -----------------
class SimpleKalman2D:
    def __init__(self, process_noise=1e-2, measurement_noise=1e-1):
        # state [x, y, vx, vy]
        self.kf = cv2.KalmanFilter(4, 2)
        dt = 1.0
        self.kf.transitionMatrix = np.array([
            [1, 0, dt, 0],
            [0, 1, 0, dt],
            [0, 0, 1, 0 ],
            [0, 0, 0, 1 ],
        ], np.float32)
        self.kf.measurementMatrix = np.array([
            [1, 0, 0, 0],
            [0, 1, 0, 0],
        ], np.float32)
        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * process_noise
        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * measurement_noise
        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 1.0
        self.initialized = False

    def correct_and_predict(self, meas):
        meas = np.array(meas, dtype=np.float32).reshape(2, 1)
        if not self.initialized:
            # init state
            self.kf.statePost = np.array([[meas[0,0]], [meas[1,0]], [0.0], [0.0]], dtype=np.float32)
            self.initialized = True
            return np.array([meas[0,0], meas[1,0]])
        self.kf.correct(meas)
        pred = self.kf.predict()
        return np.array([pred[0,0], pred[1,0]])

# ----------------- –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è UMat -----------------
def to_umat_if_available(img):
    # –∏—Å–ø–æ–ª—å–∑—É–µ–º UMat –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ ‚Äî —É—Å–∫–æ—Ä–µ–Ω–∏–µ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ OpenCV —Å OpenCL
    if hasattr(cv2, 'UMat'):
        try:
            return cv2.UMat(img)
        except:
            return img
    return img

def from_umat(x):
    if hasattr(x, 'get'):
        try:
            return x.get()
        except:
            return x
    return x

# ----------------- –§–∞–±—Ä–∏–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Ç–æ—á–µ–∫ -----------------
class FeatureDetector:
    def __init__(self, min_features=MIN_FEATURES, max_features=MAX_FEATURES):
        self.min_features = min_features
        self.max_features = max_features
        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        # –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –º–æ–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å
        self.quality_level = 0.03
        self.min_distance = 12
        self.block_size = 7

    def detect(self, gray):
        if gray is None:
            return None
        # –≤ UMat-—Ä–µ–∂–∏–º–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è get –¥–ª—è numpy –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö -> –ø—Ä–∏–º–µ–Ω—è—Ç—å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ
        # –ü—Ä–∏–º–µ–Ω–∏–º CLAHE –∏ blur
        try:
            if hasattr(gray, 'get'):
                g = from_umat(gray)
            else:
                g = gray
            enhanced = self.clahe.apply(g)
            blurred = cv2.GaussianBlur(enhanced, (3,3), 0)
            h, w = blurred.shape
            area = h*w
            # –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ maxCorners –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
            num = max(self.min_features, min(self.max_features, int(area / 600)))
            pts = cv2.goodFeaturesToTrack(
                image=blurred,
                maxCorners=num,
                qualityLevel=self.quality_level,
                minDistance=self.min_distance,
                blockSize=self.block_size,
                useHarrisDetector=False
            )
            if pts is None or len(pts) < self.min_features:
                # –æ—Å–ª–∞–±–ª—è–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è: —É–º–µ–Ω—å—à–µ–Ω–∏–µ qualityLevel –∏ minDistance
                pts = cv2.goodFeaturesToTrack(
                    image=blurred,
                    maxCorners=max(self.min_features, num),
                    qualityLevel=max(0.005, self.quality_level * 0.5),
                    minDistance=max(3, int(self.min_distance/2)),
                    blockSize=5,
                    useHarrisDetector=False
                )
            if pts is None:
                return None
            pts = pts.reshape(-1, 2)
            return pts
        except Exception as e:
            logging.debug(f"[FeatureDetector] detect failed: {e}")
            return None

# ----------------- Rope ladder waypoint management (—É–ª—É—á—à–µ–Ω–æ) -----------------
def add_waypoint(waypoints, pts, angle=None, frame_idx=None, gray=None):
    if pts is None or len(pts) < MIN_FEATURES:
        return
    wp = {
        'frame': frame_idx,
        'points': pts.copy(),
        'angle': angle,
        'center': np.mean(pts, axis=0),
        'gray': gray  # storing reference (careful with UMat)
    }
    waypoints.append(wp)
    logging.debug(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ WP (total={len(waypoints)})")

def rope_ladder_waypoint_management(waypoints, current_pts, distance_threshold=DISTANCE_THRESHOLD,
                                   anchor_center_fixed=None, frame_gray=None):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ/—É–¥–∞–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –ø–æ –ª–æ–≥–∏–∫–µ '–≤–µ—Ä—ë–≤–æ—á–Ω–æ–π –ª–µ—Å—Ç–Ω–∏—Ü—ã'.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–∞–º–∏ waypoints –∏ —Ç–µ–∫—É—â–∏–º —Ü–µ–Ω—Ç—Ä–æ–º.
    """
    if len(waypoints) == 0:
        return waypoints

    if current_pts is None or len(current_pts) == 0:
        return waypoints

    curr_center = np.mean(current_pts, axis=0)
    anchor_center = anchor_center_fixed if anchor_center_fixed is not None else waypoints[0]['center']
    current_to_anchor_dist = np.linalg.norm(curr_center - anchor_center)

    # –Ω–∞–π–¥–µ–º –±–ª–∏–∂–∞–π—à—É—é wp
    dists = np.array([np.linalg.norm(wp['center'] - curr_center) for wp in waypoints])
    closest_idx = int(np.argmin(dists))
    closest_dist = float(dists[closest_idx])

    # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ: –µ—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è —è–≤–Ω–æ –¥–∞–ª—å—à–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π (–Ω–∞ BACKTRACK_MARGIN)
    if closest_dist > distance_threshold:
        if len(waypoints) == 1:
            if current_to_anchor_dist > BACKTRACK_MARGIN:
                add_waypoint(waypoints, current_pts, frame_idx=None, gray=frame_gray)
                logging.info("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–µ—Ä–≤–∞—è –¥–æ—á–µ—Ä–Ω—è—è —Ç–æ—á–∫–∞ (–¥–≤–∏–∂–µ–Ω–∏–µ –æ—Ç —Å—Ç–∞—Ä—Ç–∞)")
        else:
            last_center = waypoints[-1]['center']
            last_to_anchor = np.linalg.norm(last_center - anchor_center)
            if current_to_anchor_dist > last_to_anchor + BACKTRACK_MARGIN:
                add_waypoint(waypoints, current_pts, frame_idx=None, gray=frame_gray)
                logging.info("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Ç–æ—á–∫–∞ (—É–¥–∞–ª–µ–Ω–∏–µ –æ—Ç —Å—Ç–∞—Ä—Ç–∞)")

    # –≤–æ–∑–≤—Ä–∞—Ç: –µ—Å–ª–∏ –±–ª–∏–∂–∞–π—à–∞—è —Ç–æ—á–∫–∞ –Ω–µ —Å—Ç–∞—Ä—Ç–æ–≤–∞—è –∏ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ (–≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å)
    elif closest_idx > 0 and closest_dist < (distance_threshold - HYSTERESIS_MARGIN):
        # –æ–±—Ä–µ–∑–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ closest_idx (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
        del waypoints[closest_idx+1:]
        logging.info(f"üîô –í–æ–∑–≤—Ä–∞—Ç –∫ —Ç–æ—á–∫–µ {closest_idx}. –£–¥–∞–ª–µ–Ω—ã –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ.")
        # –ø—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ –Ω–∞ —Ç–µ–∫—É—â–µ–º –∫–∞–¥—Ä–µ: –≤–µ—Ä–Ω—ë–º —Å–ø–∏—Å–æ–∫ waypoints
    return waypoints

# ----------------- –†–∞—Å—á—ë—Ç —É–≥–ª–∞ —á–µ—Ä–µ–∑ affine -----------------
def estimate_transform_and_angle(prev_pts, curr_pts):
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç estimateAffinePartial2D —Å RANSAC –¥–ª—è –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ–π –æ—Ü–µ–Ω–∫–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: dx, dy, angle(deg), inlier_count
    """
    if prev_pts is None or curr_pts is None:
        return 0.0, 0.0, 0.0, 0

    if len(prev_pts) < 3 or len(curr_pts) < 3:
        return 0.0, 0.0, 0.0, 0

    try:
        # ensure np.float32 Nx2
        p_prev = np.array(prev_pts, dtype=np.float32).reshape(-1,2)
        p_curr = np.array(curr_pts, dtype=np.float32).reshape(-1,2)
        # use RANSAC
        M, inliers = cv2.estimateAffinePartial2D(p_prev, p_curr, method=cv2.RANSAC, ransacReprojThreshold=6.0, maxIters=2000)
        inlier_count = 0 if inliers is None else int(inliers.sum())

        if M is None:
            return 0.0, 0.0, 0.0, inlier_count

        # affine: [ a b tx; c d ty ]
        tx = M[0,2]
        ty = M[1,2]
        # rotation from matrix
        a = M[0,0]
        b = M[0,1]
        angle_rad = np.arctan2(b, a)  # note: acos(a) is less robust
        angle_deg = np.degrees(angle_rad)
        return float(tx), float(ty), float(angle_deg), inlier_count
    except Exception as e:
        logging.debug(f"[estimate_transform_and_angle] Failed: {e}")
        return 0.0, 0.0, 0.0, 0

# ----------------- main -----------------
def main():
    logging.info("üöÄ Rope Ladder Tracker ‚Äî improved")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞—Ö–≤–∞—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    grabber = FrameGrabber(0, IMAGE_WIDTH_PX, IMAGE_HEIGHT_PX, TARGET_FPS)
    grabber.start()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ç–æ—á–µ–∫ –∏ Kalman
    feature_detector = FeatureDetector(MIN_FEATURES, MAX_FEATURES)
    kalman = SimpleKalman2D(process_noise=1e-3, measurement_noise=1e-1)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã LK (–ø–æ–¥–±–∏—Ä–∞–π –ø–æ–¥ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ)
    lk_params = dict(
        winSize=(21, 21),
        maxLevel=3,
        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.03),
        minEigThreshold=0.0001
    )

    waypoints = []
    anchor_center_fixed = None
    smoothed_curr_center = None
    prev_gray = None
    prev_tracked_pts = None
    tracked_pts = None

    tracking_active = False

    last_ladder_update_time = 0.0
    frame_idx = 0

    try:
        while True:
            ok, frame = grabber.read(timeout=1.0)
            if not ok or frame is None:
                time.sleep(FRAME_INTERVAL)
                continue

            frame_idx += 1

            # –ü—Ä–∏–º–µ–Ω—è–µ–º ROI, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω
            if ROI is not None:
                x,y,w,h = ROI
                frame_roi = frame[y:y+h, x:x+w]
            else:
                frame_roi = frame

            # –ü–µ—Ä–µ–≤–æ–¥ –≤ —Å–µ—Ä–æ–µ –∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) UMat
            gray = cv2.cvtColor(frame_roi, cv2.COLOR_BGR2GRAY)
            # try UMat
            gray_for_processing = to_umat_if_available(gray)

            tracking_now = is_tracking_enabled()
            if not tracking_now:
                if tracking_active:
                    logging.info("üî¥ –¢—Ä–µ–∫–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ.")
                    waypoints.clear()
                    anchor_center_fixed = None
                    tracking_active = False
                time.sleep(FRAME_INTERVAL)
                continue
            else:
                if not tracking_active:
                    # —Å—Ç–∞—Ä—Ç—É–µ–º —Ç—Ä–µ–∫–∏–Ω–≥: –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏
                    pts0 = feature_detector.detect(gray)
                    if pts0 is None or len(pts0) < MIN_FEATURES:
                        logging.warning("–°—Ç–∞—Ä—Ç: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–ø—É—Å–∫.")
                        time.sleep(FRAME_INTERVAL)
                        continue
                    waypoints.clear()
                    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—É—é grayscale –∫–∞–∫ —ç—Ç–∞–ª–æ–Ω (numpy)
                    add_waypoint(waypoints, pts0, frame_idx=frame_idx, gray=gray.copy())
                    anchor_center_fixed = waypoints[0]['center'].copy()
                    prev_tracked_pts = pts0.copy()
                    tracked_pts = pts0.copy()
                    prev_gray = gray.copy()
                    smoothed_curr_center = np.mean(tracked_pts, axis=0)
                    kalman = SimpleKalman2D(process_noise=1e-3, measurement_noise=1e-1)
                    kalman.correct_and_predict(smoothed_curr_center)
                    tracking_active = True
                    logging.info(f"üü¢ –¢—Ä–µ–∫–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω. Anchor at {anchor_center_fixed}")
                    continue  # –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∫–∞–¥—Ä

            # –ï—Å–ª–∏ –∞–∫—Ç–∏–≤–µ–Ω —Ç—Ä–µ–∫–∏–Ω–≥, –ø—Ä–æ–±—É–µ–º LK –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ wp.gray (–∏–ª–∏ prev_gray)
            if tracking_active:
                # choose reference gray for optical flow (prefer last wp's gray if available)
                ref_gray = waypoints[-1]['gray'] if waypoints and waypoints[-1].get('gray') is not None else prev_gray
                if ref_gray is None:
                    ref_gray = prev_gray

                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –¥–ª—è calcOpticalFlowPyrLK: Nx1x2 float32
                if tracked_pts is None or len(tracked_pts) == 0:
                    # –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –Ω–æ–≤—ã–µ —Ç–æ—á–∫–∏ –Ω–∞ —Ç–µ–∫—É—â–µ–º –∫–∞–¥—Ä–µ
                    new_pts = feature_detector.detect(gray)
                    if new_pts is None or len(new_pts) < MIN_FEATURES:
                        logging.warning("–ü–æ—Ç–µ—Ä—è —Ç—Ä–µ–∫–æ–≤: –Ω–µ—Ç –Ω–æ–≤—ã—Ö —Ç–æ—á–µ–∫.")
                        save_offset(0,0,0)
                        time.sleep(FRAME_INTERVAL)
                        continue
                    tracked_pts = new_pts.copy()

                try:
                    p0 = np.array(tracked_pts, dtype=np.float32).reshape(-1,1,2)
                    # calcOpticalFlowPyrLK –ø—Ä–∏–Ω–∏–º–∞–µ—Ç numpy images: –µ—Å–ª–∏ –±—ã–ª–∏ UMat - –∏—Å–ø–æ–ª—å–∑—É numpy
                    p1, status, err = cv2.calcOpticalFlowPyrLK(ref_gray, gray, p0, None, **lk_params)
                    if p1 is None or status is None:
                        # –ø–æ–ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –Ω–∞ —Ç–µ–∫—É—â–µ–º –∫–∞–¥—Ä–µ
                        fresh = feature_detector.detect(gray)
                        if fresh is not None and len(fresh) >= MIN_FEATURES:
                            tracked_pts = fresh.copy()
                            prev_tracked_pts = tracked_pts.copy()
                            prev_gray = gray.copy()
                            logging.info("OpticalFlow –≤–µ—Ä–Ω—É–ª None -> –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã fresh —Ç–æ—á–∫–∏.")
                            continue
                        else:
                            logging.warning("OpticalFlow –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è –∏ fresh —Ç–æ–∂–µ –Ω–µ—Ç.")
                            save_offset(0,0,0)
                            continue

                    good_idx = status.flatten() == 1
                    new_pts_valid = p1.reshape(-1,2)[good_idx]
                    prev_pts_valid = p0.reshape(-1,2)[good_idx]

                    if len(new_pts_valid) < 3 or len(prev_pts_valid) < 3:
                        # –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π, –Ω–∞–π–¥—ë–º –Ω–æ–≤—ã–µ —Ç–æ—á–∫–∏ –Ω–∞ –∫–∞–¥—Ä–µ
                        fresh = feature_detector.detect(gray)
                        if fresh is not None and len(fresh) >= MIN_FEATURES:
                            tracked_pts = fresh.copy()
                            prev_tracked_pts = tracked_pts.copy()
                            prev_gray = gray.copy()
                            logging.info("–ú–∞–ª–æ —Ö–æ—Ä–æ—à–∏—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ -> –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ—á–µ–∫.")
                            continue
                        else:
                            logging.warning("–ú–∞–ª–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∏ –Ω–µ—Ç fresh -> —Å–æ—Ö—Ä–∞–Ω—è–µ–º (0,0)")
                            save_offset(0,0,0)
                            continue

                    # –æ—Ü–µ–Ω–∏–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ–∂–¥—É prev_pts_valid –∏ new_pts_valid
                    tx, ty, angle_deg, inliers = estimate_transform_and_angle(prev_pts_valid, new_pts_valid)

                    # –¶–µ–Ω—Ç—Ä—ã
                    current_center = np.mean(new_pts_valid, axis=0)
                    if smoothed_curr_center is None:
                        smoothed_curr_center = current_center.copy()
                    else:
                        smoothed_curr_center = SMOOTHING_FACTOR * current_center + (1.0 - SMOOTHING_FACTOR) * smoothed_curr_center

                    # Kalman –∫–æ—Ä—Ä–µ–∫—Ü–∏—è + –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    kalmed = kalman.correct_and_predict(smoothed_curr_center)
                    dx_px = kalmed[0] - waypoints[-1]['center'][0]
                    dy_px = kalmed[1] - waypoints[-1]['center'][1]

                    # save offsets
                    save_offset(dx_px, dy_px, angle=angle_deg)

                    # –æ–±–Ω–æ–≤–∏–º tracked_pts –∏ prev_gray –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞
                    tracked_pts = new_pts_valid.copy()
                    prev_tracked_pts = tracked_pts.copy()
                    prev_gray = gray.copy()

                    # ladder management (—Ä–∞–∑ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª)
                    now = time.time()
                    if now - last_ladder_update_time >= LADDER_UPDATE_INTERVAL:
                        rope_ladder_waypoint_management(waypoints, tracked_pts, distance_threshold=DISTANCE_THRESHOLD,
                                                        anchor_center_fixed=anchor_center_fixed, frame_gray=gray.copy())
                        last_ladder_update_time = now

                    # –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                    logging.debug(f"Inliers={inliers} | dx={dx_px:.2f} dy={dy_px:.2f} angle={angle_deg:.2f} | pts={len(tracked_pts)}")
                except Exception as e:
                    logging.warning(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ä–∞—Å—á—ë—Ç–∞ OpticalFlow/Transform: {e}")
                    save_offset(0,0,0)
                    prev_gray = gray.copy()
                    time.sleep(FRAME_INTERVAL)
                    continue

            # –Ω–µ–±–æ–ª—å—à–æ–π sleep —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Ü–∏–∫–ª
            time.sleep(FRAME_INTERVAL * 0.2)

    except KeyboardInterrupt:
        logging.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)
    finally:
        grabber.stop()
        logging.info("–°–∏—Å—Ç–µ–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    return 0

if __name__ == "__main__":
    exit(main())
