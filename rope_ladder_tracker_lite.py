#!/usr/bin/env python3
import cv2
import numpy as np
import time
import logging
import json
import os

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–ª–∞–±—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤ (Luckfox) ---
IMAGE_WIDTH_PX = 640
IMAGE_HEIGHT_PX = 480
TARGET_FPS = 30
FRAME_INTERVAL = 1.0 / TARGET_FPS

MIN_FEATURES = 50
MAX_FEATURES = 150
DISTANCE_THRESHOLD = 12.0        # –ø–æ—Ä–æ–≥ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è/–≤–æ–∑–≤—Ä–∞—Ç–∞ (–ø–∏–∫—Å–µ–ª–∏)
BACKTRACK_MARGIN = 6.0           # –∑–∞–ø–∞—Å –¥–ª—è –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è –≤–ø–µ—Ä—ë–¥
RETURN_HYSTERESIS = 2.0          # –≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ (—á—Ç–æ–±—ã –Ω–µ –¥—ë—Ä–≥–∞–ª—Å—è)

CLAHE_ENABLED = True
CLAHE_CLIP = 3.0
CLAHE_TILE = (8, 8)

# –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –º–∞—Å—à—Ç–∞–±: –¥–ª—è –∫–∞–º–µ—Ä—ã —Å FOV 70¬∞ –∏ –≤—ã—Å–æ—Ç—ã 50‚Äì100 –º
# 1 –ø–∏–∫—Å–µ–ª ‚âà 0.02‚Äì0.05 –º –Ω–∞ –∑–µ–º–ª–µ. –ú–æ–∂–Ω–æ –∫–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å.
# –ú—ã –Ω–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–µ—Ç—Ä—ã, –Ω–æ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤—ã–±—Ä–æ—Å—ã –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏.
MAX_PIXEL_VELOCITY = 30  # max –¥–æ–ø—É—Å—Ç–∏–º–æ–µ —Å–º–µ—â–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –∑–∞ –∫–∞–¥—Ä (–ø–∏–∫—Å–µ–ª–∏)

FLAG_PATH = '/home/orangepi/tracking_enabled.flag'

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler("rope_ladder.log"),
        logging.StreamHandler()
    ]
)

def is_tracking_enabled():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–ª–∞–≥ –≤–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–µ–∫–∏–Ω–≥–∞"""
    try:
        with open(FLAG_PATH, 'r') as f:
            return f.read().strip() == '1'
    except:
        return False

def save_offset(x_px, y_px, angle=0.0):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–º–µ—â–µ–Ω–∏–µ –≤ –ø–∏–∫—Å–µ–ª—è—Ö (–∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä)"""
    data = {
        'x': int(x_px),
        'y': int(y_px),
        'angle': float(angle)
    }
    temp_file = 'offsets_tmp.json'
    final_file = 'offsets.json'
    try:
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)
        os.replace(temp_file, final_file)
    except Exception as e:
        logging.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å offset: {e}")

def create_fast_detector():
    """–°–æ–∑–¥–∞—ë—Ç –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç FAST –æ–¥–∏–Ω —Ä–∞–∑ (—ç–∫–æ–Ω–æ–º–∏—è CPU)"""
    fast = cv2.FastFeatureDetector_create()
    fast.setNonmaxSuppression(True)
    return fast

def adaptive_clahe(gray, clip_limit=3.0):
    """–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π CLAHE —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç—É"""
    if gray.mean() < 40:
        # –û—á–µ–Ω—å —Ç—ë–º–Ω–æ ‚Äî —É–º–µ–Ω—å—à–∞–µ–º clip, —á—Ç–æ–±—ã –Ω–µ —É—Å–∏–ª–∏–≤–∞—Ç—å —à—É–º
        clip = min(clip_limit, 1.5)
    elif gray.mean() > 200:
        # –û—á–µ–Ω—å —Å–≤–µ—Ç–ª–æ ‚Äî —É–º–µ—Ä–µ–Ω–Ω—ã–π CLAHE
        clip = min(clip_limit, 2.0)
    else:
        clip = clip_limit

    clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=(8, 8))
    return clahe.apply(gray)

def normalize_illumination(gray):
    """–õ–æ–∫–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏ (—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —Ç–µ–Ω—è–º)"""
    # –ë–ª—é—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ñ–æ–Ω–æ–≤–æ–π –æ—Å–≤–µ—â—ë–Ω–Ω–æ—Å—Ç–∏
    background = cv2.GaussianBlur(gray, (127, 127), 15)
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º: gray - background + 127
    normalized = cv2.addWeighted(gray, 1.0, background, -1.0, 127)
    return np.clip(normalized, 0, 255).astype(np.uint8)

def enhance_and_detect_features(gray, fast_detector):
    """–£–ª—É—á—à–µ–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Å —É–ø–æ—Ä–æ–º –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å"""
    if CLAHE_ENABLED:
        gray = adaptive_clahe(gray)
    gray = normalize_illumination(gray)

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ FAST
    mean_val = cv2.mean(gray)[0]
    if mean_val < 30:
        threshold = 10
    elif mean_val < 80:
        threshold = 15
    elif mean_val < 160:
        threshold = 20
    else:
        threshold = 25
    fast_detector.setThreshold(threshold)

    points = fast_detector.detect(gray, None)
    if not points:
        return None

    pts = np.array([[p.pt[0], p.pt[1]] for p in points], dtype=np.float32)

    # –§–∏–ª—å—Ç—Ä –ø–æ –∫—Ä–∞—è–º (—Å –∑–∞–ø–∞—Å–æ–º 20 –ø–∏–∫—Å–µ–ª–µ–π)
    h, w = gray.shape
    margin = 20
    mask = (pts[:, 0] > margin) & (pts[:, 0] < w - margin) & \
           (pts[:, 1] > margin) & (pts[:, 1] < h - margin)
    pts = pts[mask]

    if len(pts) == 0:
        return None

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É–≥–ª—É (–∏–∑–±–µ–≥–∞–µ–º –ª–∏–Ω–∏–π)
    if len(pts) > 10:
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Å–æ—Å–µ–¥–µ–π
        from scipy.spatial.distance import pdist, squareform
        dists = squareform(pdist(pts))
        np.fill_diagonal(dists, np.inf)
        nearest_dists = np.min(dists, axis=1)
        mean_nearest = np.mean(nearest_dists)
        # –û—Ç—Å–µ–∏–≤–∞–µ–º —Å–ª–∏—à–∫–æ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–µ (–ª–∏–Ω–∏–∏, —Å–µ—Ç–∫–∏)
        if np.std(nearest_dists) < 0.3 * mean_nearest and len(pts) > 100:
            # –í–µ—Ä–æ—è—Ç–Ω–æ, —Ä–µ–≥—É–ª—è—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ ‚Äî —É–º–µ–Ω—å—à–∞–µ–º
            idx = np.random.choice(len(pts), size=min(80, len(pts)), replace=False)
            pts = pts[idx]

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    if len(pts) > MAX_FEATURES:
        scores = [cv2.FastFeatureDetector_create().compute(gray, [cv2.KeyPoint(x, y, 3)])[1][0] for x, y in pts]
        idx = np.argsort(scores)[::-1][:MAX_FEATURES]
        pts = pts[idx]

    return pts.reshape(-1, 1, 2).astype(np.float32)

def add_waypoint(waypoints, points, frame_idx=None):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–æ—á–∫—É –Ω–∞ –ª–µ—Å—Ç–Ω–∏—Ü—É"""
    if points is None or len(points) == 0:
        return
    center = np.mean(points.reshape(-1, 2), axis=0)
    wp = {
        'frame': frame_idx,
        'points': np.array(points, copy=True),
        'center': center
    }
    waypoints.append(wp)

def rope_ladder_waypoint_management(waypoints, current_points, distance_threshold=DISTANCE_THRESHOLD):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ—á–∫–∞–º–∏ –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É –≤–µ—Ä—ë–≤–æ—á–Ω–æ–π –ª–µ—Å—Ç–Ω–∏—Ü—ã —Å –≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å–æ–º"""
    if len(waypoints) == 0 or current_points is None or len(current_points) == 0:
        return waypoints

    curr_center = np.mean(current_points.reshape(-1, 2), axis=0)
    anchor_center = waypoints[0]['center']

    # –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–π —Ç–æ—á–∫–∏ –≤ –ª–µ—Å—Ç–Ω–∏—Ü–µ
    closest_idx = 0
    min_dist = np.inf
    for i, wp in enumerate(waypoints):
        dist = np.linalg.norm(wp['center'] - curr_center)
        if dist < min_dist:
            min_dist = dist
            closest_idx = i

    # –í–æ–∑–≤—Ä–∞—Ç, –µ—Å–ª–∏ –±–ª–∏–∂–µ –ø–æ—Ä–æ–≥–∞
    if min_dist < distance_threshold and closest_idx > 0:
        waypoints[:] = waypoints[:closest_idx + 1]
        logging.info(f"üîô –í–æ–∑–≤—Ä–∞—Ç –∫ —Ç–æ—á–∫–µ {closest_idx} (dist={min_dist:.1f}px)")
        return waypoints

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ –≤–ø–µ—Ä—ë–¥ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–∞—Ä—Ç–∞)
    last_center = waypoints[-1]['center']
    dist_last_to_anchor = np.linalg.norm(last_center - anchor_center)
    dist_curr_to_anchor = np.linalg.norm(curr_center - anchor_center)

    # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–æ–¥–≤–∏–Ω—É–ª–∏—Å—å –¥–∞–ª—å—à–µ (—Å –∑–∞–ø–∞—Å–æ–º)
    if dist_curr_to_anchor > dist_last_to_anchor + BACKTRACK_MARGIN:
        add_waypoint(waypoints, current_points)
        logging.info(f"‚ûï –ù–æ–≤–∞—è —Ç–æ—á–∫–∞: dist_to_start={dist_curr_to_anchor:.1f}px")

    return waypoints

def main():
    logging.info("ü™ú Rope Ladder Tracker: —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è Luckfox (Cortex-A7)")

    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, IMAGE_WIDTH_PX)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, IMAGE_HEIGHT_PX)
    cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    if not cap.isOpened():
        logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É.")
        return 1

    ret, frame = cap.read()
    if not ret or frame is None:
        logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä.")
        return 1

    frame = cv2.resize(frame, (IMAGE_WIDTH_PX, IMAGE_HEIGHT_PX))
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # –°–æ–∑–¥–∞—ë–º FAST –æ–¥–∏–Ω —Ä–∞–∑
    fast_detector = create_fast_detector()

    tracked_points = enhance_and_detect_features(gray, fast_detector)
    if tracked_points is None or len(tracked_points) < MIN_FEATURES:
        logging.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ.")
        return 1

    prev_gray = gray.copy()
    frame_idx = 0

    # ü™ú –í–µ—Ä—ë–≤–æ—á–Ω–∞—è –ª–µ—Å—Ç–Ω–∏—Ü–∞
    waypoints = []
    add_waypoint(waypoints, tracked_points, frame_idx=0)

    # ‚öôÔ∏è LK –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–ª—ë–≥–∫–∏–µ)
    lk_params = dict(
        winSize=(15, 15),
        maxLevel=2,
        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 15, 0.03)
    )

    # EMA —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è —Å–º–µ—â–µ–Ω–∏—è (—É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥—Ä–µ–±–µ–∑–≥–∞)
    alpha = 0.3  # —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (–º–µ–Ω—å—à–µ = —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ, –±–æ–ª—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ —Ä–µ–∞–∫—Ü–∏—è)
    smoothed_dx, smoothed_dy = 0.0, 0.0

    fps = 0.0
    frame_count = 0
    start_time = time.time()

    tracking_active = False
    last_valid_center = None

    try:
        while True:
            loop_start = time.time()

            ret, frame = cap.read()
            if not ret or frame is None:
                logging.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –∫–∞–¥—Ä ‚Äî –ø—Ä–æ–ø—É—Å–∫")
                time.sleep(FRAME_INTERVAL)
                continue

            frame = cv2.resize(frame, (IMAGE_WIDTH_PX, IMAGE_HEIGHT_PX))
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–ª–∞–≥–∞
            tracking_now = is_tracking_enabled()
            if not tracking_now:
                if tracking_active:
                    logging.info("üî¥ –¢—Ä–µ–∫–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –°–±—Ä–æ—Å waypoints.")
                    waypoints.clear()
                save_offset(0, 0)
                tracking_active = False
                prev_gray = gray
                time.sleep(FRAME_INTERVAL)
                continue
            else:
                if not tracking_active:
                    logging.info("üü¢ –¢—Ä–µ–∫–∏–Ω–≥ –≤–∫–ª—é—á—ë–Ω. –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫.")
                    fresh_points = enhance_and_detect_features(gray, fast_detector)
                    if fresh_points is not None and len(fresh_points) >= MIN_FEATURES:
                        waypoints.clear()
                        add_waypoint(waypoints, fresh_points, frame_idx=0)
                        tracked_points = fresh_points.copy()
                        last_valid_center = np.mean(fresh_points.reshape(-1, 2), axis=0)
                        smoothed_dx = smoothed_dy = 0.0
                        logging.info("üîÑ –ù–æ–≤—ã–π —Å—Ç–∞—Ä—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
                        tracking_active = True
                    else:
                        logging.warning("‚ö†Ô∏è –ù–µ—Ç —Ç–æ—á–µ–∫ –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫")
                        save_offset(0, 0)
                        prev_gray = gray
                        continue
                tracking_active = True

            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ
            new_points, status, _ = cv2.calcOpticalFlowPyrLK(
                prev_gray, gray, tracked_points, None, **lk_params
            )
            if new_points is None or status is None:
                prev_gray = gray
                continue

            good_indices = [i for i, s in enumerate(status) if s == 1]
            tracked_points = new_points[good_indices]

            prev_gray = gray

            if len(tracked_points) < MIN_FEATURES:
                save_offset(0, 0)
                logging.warning("‚ö†Ô∏è –ú–∞–ª–æ —Ç–æ—á–µ–∫ ‚Äî —Å–±—Ä–æ—Å")
                continue

            current_center = np.mean(tracked_points.reshape(-1, 2), axis=0)

            # –ó–∞—â–∏—Ç–∞ –æ—Ç —Ä–µ–∑–∫–∏—Ö –ø—Ä—ã–∂–∫–æ–≤ (–≤—ã–±—Ä–æ—Å—ã)
            if last_valid_center is not None:
                velocity = np.linalg.norm(current_center - last_valid_center)
                if velocity > MAX_PIXEL_VELOCITY:
                    logging.warning(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ ({velocity:.1f}px) ‚Äî –ø—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–∞")
                    continue
            last_valid_center = current_center

            # ü™ú –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–µ—Å—Ç–Ω–∏—Ü–µ–π
            rope_ladder_waypoint_management(waypoints, tracked_points)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ —Å—Ç–∞—Ä—Ç—É
            try:
                anchor_center = waypoints[0]['center']
                dist_to_start = np.linalg.norm(current_center - anchor_center)
            except:
                save_offset(0, 0)
                continue

            if dist_to_start < DISTANCE_THRESHOLD - RETURN_HYSTERESIS:
                dx_px, dy_px = 0.0, 0.0
                logging.info(f"üéØ –í–û–ó–í–†–ê–¢ –í –°–¢–ê–†–¢! (dist={dist_to_start:.1f}px)")
            else:
                dx_px = anchor_center[0] - current_center[0]
                dy_px = anchor_center[1] - current_center[1]

            # EMA —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
            smoothed_dx = alpha * dx_px + (1 - alpha) * smoothed_dx
            smoothed_dy = alpha * dy_px + (1 - alpha) * smoothed_dy

            save_offset(smoothed_dx, smoothed_dy)

            # FPS
            frame_count += 1
            elapsed = time.time() - start_time
            if elapsed >= 1.0:
                fps = frame_count / elapsed
                logging.info(f"üìä {fps:.1f} FPS | dx={int(smoothed_dx):+6d} | dy={int(smoothed_dy):+6d} | WPs={len(waypoints)}")
                frame_count = 0
                start_time = time.time()

            loop_time = time.time() - loop_start
            if loop_time < FRAME_INTERVAL:
                time.sleep(FRAME_INTERVAL - loop_time)

    except KeyboardInterrupt:
        logging.info("üõë –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
    except Exception as e:
        logging.error(f"üí• –û—à–∏–±–∫–∞: {e}", exc_info=True)
    finally:
        cap.release()
        logging.info("üëã –°–∏—Å—Ç–µ–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    return 0

if __name__ == "__main__":
    exit(main())