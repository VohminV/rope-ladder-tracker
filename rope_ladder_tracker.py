#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°—Ç–∞–±–∏–ª—å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –ª–µ—Å—Ç–Ω–∏—Ü—ã –¥–ª—è Orange Pi 5: —É–ª—É—á—à–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –æ—Å–≤–µ—â–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –≤–∏–±—Ä–∞—Ü–∏–∏.
- –ó–∞–º–µ–Ω–∞ goodFeaturesToTrack –Ω–∞ FAST + BRISK
- –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: CLAHE + Bilateral + Adaptive Threshold
- –£—Å—Ç–æ–π—á–∏–≤—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –≤–∏–±—Ä–∞—Ü–∏–π
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ª–µ—Å–µ–Ω–∫–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π Kalman-—Ñ–∏–ª—å—Ç—Ä
"""

import cv2
import numpy as np
import time
import logging
import json
import os
import math

# ----------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ -----------------
IMAGE_WIDTH_PX = 640
IMAGE_HEIGHT_PX = 480
TARGET_FPS = 20
FRAME_INTERVAL = 1.0 / TARGET_FPS

MIN_FEATURES = 25
MAX_FEATURES = 1000
DISTANCE_THRESHOLD = 40.0
BACKTRACK_MARGIN = 25.0
HYSTERESIS_MARGIN = 12.0
LADDER_UPDATE_INTERVAL = 0.8

INLIER_SAVE_RATIO = 0.35
MIN_INLIER_COUNT = 10

FLAG_PATH = 'tracking_enabled.flag'
OFFSETS_FILE = 'offsets.json'
ROI = None

SAVE_MODE = 'last'
DEBUG = True
SAVE_IN_METERS = False
CURRENT_HEIGHT_M = None
CAMERA_FOV_DEG = 70.0

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)-5s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("rope_ladder_stable.log", mode='w', encoding='utf-8')
    ]
)

# ----------------- –£—Ç–∏–ª–∏—Ç—ã -----------------
def px_to_m(dx_px, dy_px, height_m, fov_deg=CAMERA_FOV_DEG, img_w=IMAGE_WIDTH_PX):
    if height_m is None or height_m <= 0:
        return dx_px, dy_px
    half_fov_rad = math.radians(fov_deg) / 2.0
    width_m = 2.0 * height_m * math.tan(half_fov_rad)
    m_per_px = width_m / float(img_w)
    return dx_px * m_per_px, dy_px * m_per_px

def save_offset(dx, dy, angle=0.0, in_meters=False):
    data = {
        'x': float(dx), 'y': float(dy), 'angle': float(angle),
        'units': 'meters' if in_meters else 'pixels', 'ts': time.time()
    }
    tmp = OFFSETS_FILE + '.tmp'
    try:
        with open(tmp, 'w') as f:
            json.dump(data, f, indent=2)
        os.replace(tmp, OFFSETS_FILE)
    except Exception as e:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å offsets: {e}")

def is_tracking_enabled():
    try:
        with open(FLAG_PATH, 'r') as f:
            return f.read().strip() == '1'
    except:
        return False

# ----------------- –£–ª—É—á—à–µ–Ω–Ω—ã–π Kalman —Ñ–∏–ª—å—Ç—Ä -----------------
class EnhancedKalman2D:
    def __init__(self, process_noise=1e-3, measurement_noise=1e-1):
        self.kf = cv2.KalmanFilter(4, 2)
        dt = 1.0
        self.kf.transitionMatrix = np.array([
            [1, 0, dt, 0],
            [0, 1, 0, dt],
            [0, 0, 1, 0],
            [0, 0, 0, 1]
        ], np.float32)
        self.kf.measurementMatrix = np.array([[1,0,0,0], [0,1,0,0]], np.float32)
        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * process_noise
        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * measurement_noise
        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 1.0
        self.initialized = False

    def correct_and_predict(self, meas):
        meas = np.array(meas, dtype=np.float32).reshape(2, 1)
        if not self.initialized:
            self.kf.statePost = np.array([[meas[0,0]], [meas[1,0]], [0.0], [0.0]])
            self.initialized = True
            return np.array([meas[0,0], meas[1,0]])
        self.kf.correct(meas)
        pred = self.kf.predict()
        return np.array([pred[0,0], pred[1,0]])

# ----------------- –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä FAST + BRISK -----------------
class FastBriskDetector:
    def __init__(self, min_features=MIN_FEATURES, max_features=MAX_FEATURES):
        self.min_features = min_features
        self.max_features = max_features
        self.fast = cv2.FastFeatureDetector_create(threshold=10, nonmaxSuppression=True)
        self.brisk = cv2.BRISK_create()
        self.clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))

    def detect(self, gray):
        if gray is None:
            return None

        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        brightness = np.mean(gray)
        denoised = cv2.bilateralFilter(gray, 9, 75, 75)
        
        if brightness < 80:
            # –¢–µ–º–Ω–æ: —Å–∏–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
            enhanced = self.clahe.apply(denoised)
            detection_img = enhanced
        else:
            enhanced = self.clahe.apply(denoised)
            detection_img = enhanced

        # –î–µ—Ç–µ–∫—Ü–∏—è FAST
        keypoints = self.fast.detect(detection_img, None)
        if keypoints is None or len(keypoints) < self.min_features:
            return None

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
        keypoints = sorted(keypoints, key=lambda x: -x.response)
        keypoints = keypoints[:self.max_features]
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ BRISK
        _, descriptors = self.brisk.compute(detection_img, keypoints)
        if descriptors is None:
            return None
            
        pts = np.array([kp.pt for kp in keypoints], dtype=np.float32)
        return pts

# ----------------- –£—Å—Ç–æ–π—á–∏–≤—ã–π —Ç—Ä–µ–∫–µ—Ä —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π -----------------
class RobustTracker:
    def __init__(self):
        self.lk_params = dict(
            winSize=(21, 21),
            maxLevel=3,
            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)
        )
        self.window_size = 5
        self.history = []

    def track(self, prev_gray, curr_gray, prev_pts):
        if prev_pts is None or len(prev_pts) < 8:
            return None, 0, None

        p0 = np.array(prev_pts, dtype=np.float32).reshape(-1, 1, 2)
        p1, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, p0, None, **self.lk_params)
        
        if p1 is None or status is None or len(p1) == 0:
            return None, 0, None

        good = status.flatten() == 1
        if not np.any(good):
            return None, 0, None

        new_pts = p1.reshape(-1, 2)[good]
        old_pts = p0.reshape(-1, 2)[good]
        
        if len(new_pts) < MIN_FEATURES:
            return None, 0, None

        # –û—Ü–µ–Ω–∫–∞ –∞—Ñ—Ñ–∏–Ω–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        M, mask = cv2.estimateAffinePartial2D(old_pts, new_pts, method=cv2.RANSAC, ransacReprojThreshold=6.0)
        inliers = mask.sum() if mask is not None else 0
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∏–±—Ä–∞—Ü–∏–π)
        center = np.mean(new_pts, axis=0)
        self.history.append(center)
        if len(self.history) > self.window_size:
            self.history.pop(0)
            
        if len(self.history) == self.window_size:
            smoothed_center = np.mean(self.history, axis=0)
        else:
            smoothed_center = center
            
        return new_pts, inliers, smoothed_center

# ----------------- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ª–µ—Å–µ–Ω–∫–∏ -----------------
def rope_ladder_waypoint_management(waypoints, current_center, anchor_center_fixed, distance_threshold=DISTANCE_THRESHOLD):
    if len(waypoints) == 0:
        return waypoints

    current_to_anchor = np.linalg.norm(current_center - anchor_center_fixed)
    last_center = waypoints[-1]['center']
    last_to_anchor = np.linalg.norm(last_center - anchor_center_fixed)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π —Å—Ç—É–ø–µ–Ω—å–∫–∏
    if current_to_anchor > last_to_anchor + BACKTRACK_MARGIN:
        wp = {
            'center': current_center.copy(),
            'timestamp': time.time(),
            'cumulative': waypoints[-1]['cumulative'] + (current_center - last_center)
        }
        waypoints.append(wp)
        logging.info("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Ç–æ—á–∫–∞ –ª–µ—Å—Ç–Ω–∏—Ü—ã")
    
    # –í–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—É–ø–µ–Ω—å–∫–µ
    elif len(waypoints) > 1:
        dist_to_prev = np.linalg.norm(current_center - waypoints[-2]['center'])
        if dist_to_prev < HYSTERESIS_MARGIN:
            del waypoints[-1]
            logging.info(f"üîô –í–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ç–æ—á–∫–µ (–æ—Å—Ç–∞–ª–æ—Å—å: {len(waypoints)})")
    
    return waypoints

# ----------------- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª -----------------
def main():
    logging.info("üöÄ –°—Ç–∞–±–∏–ª—å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –ª–µ—Å—Ç–Ω–∏—Ü—ã ‚Äî –∑–∞–ø—É—Å–∫")
    
    detector = FastBriskDetector(MIN_FEATURES, MAX_FEATURES)
    tracker = RobustTracker()
    kalman = EnhancedKalman2D(process_noise=1e-3, measurement_noise=1e-1)
    
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, IMAGE_WIDTH_PX)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, IMAGE_HEIGHT_PX)
    cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)
    
    waypoints = []
    anchor_center_fixed = None
    tracking_active = False
    last_update_time = 0
    dx_px, dy_px = 0.0, 0.0
    angle_deg = 0.0
    
    prev_gray = None
    tracked_pts = None
    frame_idx = 0

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                time.sleep(FRAME_INTERVAL)
                continue
                
            frame_idx += 1
            frame_roi = frame if ROI is None else frame[ROI[1]:ROI[1]+ROI[3], ROI[0]:ROI[0]+ROI[2]]
            gray = cv2.cvtColor(frame_roi, cv2.COLOR_BGR2GRAY)
            
            if not is_tracking_enabled():
                if tracking_active:
                    logging.info("üî¥ –¢—Ä–µ–∫–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                    waypoints.clear()
                    tracking_active = False
                time.sleep(FRAME_INTERVAL)
                continue
                
            if not tracking_active:
                pts = detector.detect(gray)
                if pts is not None and len(pts) >= MIN_FEATURES:
                    waypoints = [{'center': np.mean(pts, axis=0), 'cumulative': np.array([0.0, 0.0])}]
                    anchor_center_fixed = waypoints[0]['center'].copy()
                    tracked_pts = pts
                    prev_gray = gray.copy()
                    kalman = EnhancedKalman2D(process_noise=1e-3, measurement_noise=1e-1)
                    kalman.correct_and_predict(anchor_center_fixed)
                    tracking_active = True
                    logging.info(f"üü¢ –¢—Ä–µ–∫–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω. –Ø–∫–æ—Ä—å: {anchor_center_fixed}")
                else:
                    logging.debug("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫")
                time.sleep(FRAME_INTERVAL)
                continue

            # –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–∫–∏–Ω–≥
            new_pts, inliers, smoothed_center = tracker.track(prev_gray, gray, tracked_pts)
            
            if new_pts is None or len(new_pts) < MIN_FEATURES or smoothed_center is None:
                logging.info("–ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–∞")
                new_pts = detector.detect(gray)
                if new_pts is not None and len(new_pts) >= MIN_FEATURES:
                    tracked_pts = new_pts
                    prev_gray = gray.copy()
                    continue
                else:
                    save_offset(0, 0, 0)
                    time.sleep(FRAME_INTERVAL)
                    continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ inliers
            min_inliers = max(MIN_INLIER_COUNT, len(new_pts) * INLIER_SAVE_RATIO)
            if inliers < min_inliers:
                logging.warning(f"–ù–∏–∑–∫–∏–µ inliers ({inliers} < {min_inliers}) -> –ø—Ä–æ–ø—É—Å–∫")
                save_offset(dx_px, dy_px, angle_deg, in_meters=SAVE_IN_METERS and CURRENT_HEIGHT_M is not None)
            else:
                kalmed = kalman.correct_and_predict(smoothed_center)
                last_center = waypoints[-1]['center']
                offset = kalmed - last_center
                
                if SAVE_MODE == 'last':
                    dx_px, dy_px = float(offset[0]), float(offset[1])
                else:
                    total = waypoints[-1]['cumulative'] + offset
                    dx_px, dy_px = float(total[0]), float(total[1])

                if SAVE_IN_METERS and CURRENT_HEIGHT_M is not None:
                    dx_m, dy_m = px_to_m(dx_px, dy_px, CURRENT_HEIGHT_M)
                    save_offset(dx_m, dy_m, angle_deg, in_meters=True)
                else:
                    save_offset(dx_px, dy_px, angle_deg, in_meters=False)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª–µ—Å—Ç–Ω–∏—Ü—ã
            now = time.time()
            if now - last_update_time >= LADDER_UPDATE_INTERVAL:
                rope_ladder_waypoint_management(waypoints, smoothed_center, anchor_center_fixed)
                last_update_time = now

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            if DEBUG:
                debug_frame = frame.copy()
                for i, wp in enumerate(waypoints):
                    center = tuple(map(int, wp['center']))
                    cv2.circle(debug_frame, center, 6, (0,255,0), -1)
                    cv2.putText(debug_frame, f"W{i}", (center[0]+5, center[1]-5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
                
                # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–∫–∞–ª—è—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                state = kalman.kf.statePost[:2].flatten()
                kalmed_int = (int(state[0]), int(state[1]))
                cv2.circle(debug_frame, kalmed_int, 8, (0,0,255), -1)
                cv2.imshow("DEBUG", debug_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            tracked_pts = new_pts
            prev_gray = gray.copy()
            time.sleep(max(0, FRAME_INTERVAL - (time.time() - now)))

    except KeyboardInterrupt:
        logging.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)
    finally:
        cap.release()
        cv2.destroyAllWindows()
        logging.info("–°–∏—Å—Ç–µ–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

if __name__ == "__main__":
    main()