#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°—Ç–∞–±–∏–ª—å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –ª–µ—Å—Ç–Ω–∏—Ü—ã –¥–ª—è Orange Pi 5: —É–ª—É—á—à–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –æ—Å–≤–µ—â–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –≤–∏–±—Ä–∞—Ü–∏–∏.
- –ó–∞–º–µ–Ω–∞ goodFeaturesToTrack –Ω–∞ FAST + BRISK
- –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: CLAHE + Bilateral + Adaptive Threshold
- –£—Å—Ç–æ–π—á–∏–≤—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –≤–∏–±—Ä–∞—Ü–∏–π
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ª–µ—Å–µ–Ω–∫–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π Kalman-—Ñ–∏–ª—å—Ç—Ä
- –¶–µ–Ω—Ç—Ä –º–∞—Å—Å —Ç–æ—á–µ–∫ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ waypoint
"""

import cv2
import numpy as np
import time
import logging
import json
import os
import math
from collections import deque

# ----------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ -----------------
IMAGE_WIDTH_PX = 640
IMAGE_HEIGHT_PX = 480
TARGET_FPS = 20
FRAME_INTERVAL = 1.0 / TARGET_FPS

MIN_FEATURES = 25
MAX_FEATURES = 1000
DISTANCE_THRESHOLD = 40.0
BACKTRACK_MARGIN = 25.0
HYSTERESIS_MARGIN = 12.0
LADDER_UPDATE_INTERVAL = 0.8

INLIER_SAVE_RATIO = 0.5
MIN_INLIER_COUNT = 15

FLAG_PATH = 'tracking_enabled.flag'
OFFSETS_FILE = 'offsets.json'
ROI = None

SAVE_MODE = 'last'
DEBUG = False
SAVE_IN_METERS = False
CURRENT_HEIGHT_M = None
CAMERA_FOV_DEG = 70.0

# –ë—É—Ñ–µ—Ä –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–º–µ—â–µ–Ω–∏–π (dx, dy)
OFFSET_BUFFER_SIZE = 20
offset_buffer = deque(maxlen=OFFSET_BUFFER_SIZE)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)-5s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("rope_ladder_stable.log", mode='w', encoding='utf-8')
    ]
)

# ----------------- –£—Ç–∏–ª–∏—Ç—ã -----------------
def px_to_m(dx_px, dy_px, height_m, fov_deg=CAMERA_FOV_DEG, img_w=IMAGE_WIDTH_PX):
    if height_m is None or height_m <= 0:
        return dx_px, dy_px
    half_fov_rad = math.radians(fov_deg) / 2.0
    width_m = 2.0 * height_m * math.tan(half_fov_rad)
    m_per_px = width_m / float(img_w)
    return dx_px * m_per_px, dy_px * m_per_px

def save_offset(dx, dy, angle=0.0, in_meters=False):
    data = {
        'x': int(dx), 'y': int(dy), 'angle': float(angle),
        'units': 'meters' if in_meters else 'pixels', 'ts': time.time()
    }
    tmp = OFFSETS_FILE + '.tmp'
    try:
        with open(tmp, 'w') as f:
            json.dump(data, f, indent=2)
        os.replace(tmp, OFFSETS_FILE)
    except Exception as e:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å offsets: {e}")

def is_tracking_enabled():
    try:
        with open(FLAG_PATH, 'r') as f:
            return f.read().strip() == '1'
    except:
        return False

# ----------------- –£–ª—É—á—à–µ–Ω–Ω—ã–π Kalman —Ñ–∏–ª—å—Ç—Ä -----------------
class EnhancedKalman2D:
    def __init__(self, process_noise=1e-3, measurement_noise=1e-1):
        self.kf = cv2.KalmanFilter(4, 2)
        dt = 1.0
        self.kf.transitionMatrix = np.array([
            [1, 0, dt, 0],
            [0, 1, 0, dt],
            [0, 0, 1, 0],
            [0, 0, 0, 1]
        ], np.float32)
        self.kf.measurementMatrix = np.array([[1,0,0,0], [0,1,0,0]], np.float32)
        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * process_noise
        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * measurement_noise
        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 1.0
        self.initialized = False

    def correct_and_predict(self, meas):
        meas = np.array(meas, dtype=np.float32).reshape(2, 1)
        if not self.initialized:
            self.kf.statePost = np.array([[meas[0,0]], [meas[1,0]], [0.0], [0.0]])
            self.initialized = True
            return np.array([meas[0,0], meas[1,0]])
        self.kf.correct(meas)
        pred = self.kf.predict()
        return np.array([pred[0,0], pred[1,0]])

# ----------------- –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä FAST + BRISK -----------------
class FastBriskDetector:
    def __init__(self, min_features=MIN_FEATURES, max_features=MAX_FEATURES):
        self.min_features = min_features
        self.max_features = max_features
        self.fast = cv2.FastFeatureDetector_create(threshold=10, nonmaxSuppression=True)
        self.brisk = cv2.BRISK_create()
        self.clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))

    def detect(self, gray):
        if gray is None:
            return None

        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        brightness = np.mean(gray)
        denoised = cv2.bilateralFilter(gray, 9, 75, 75)
        
        if brightness < 80:
            # –¢–µ–º–Ω–æ: —Å–∏–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
            enhanced = self.clahe.apply(denoised)
            detection_img = enhanced
        else:
            enhanced = self.clahe.apply(denoised)
            detection_img = enhanced

        # –î–µ—Ç–µ–∫—Ü–∏—è FAST
        keypoints = self.fast.detect(detection_img, None)
        if keypoints is None or len(keypoints) < self.min_features:
            return None

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
        keypoints = sorted(keypoints, key=lambda x: -x.response)
        keypoints = keypoints[:self.max_features]
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ BRISK
        _, descriptors = self.brisk.compute(detection_img, keypoints)
        if descriptors is None:
            return None
            
        pts = np.array([kp.pt for kp in keypoints], dtype=np.float32)
        return pts

# ----------------- –£—Å—Ç–æ–π—á–∏–≤—ã–π —Ç—Ä–µ–∫–µ—Ä —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π -----------------
class RobustTracker:
    def __init__(self):
        self.lk_params = dict(
            winSize=(21, 21),
            maxLevel=3,
            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)
        )
        self.window_size = 5
        self.history = []

    def track(self, prev_gray, curr_gray, prev_pts):
        if prev_pts is None or len(prev_pts) < 8:
            return None, 0, None

        p0 = np.array(prev_pts, dtype=np.float32).reshape(-1, 1, 2)
        p1, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, p0, None, **self.lk_params)
        
        if p1 is None or status is None or len(p1) == 0:
            return None, 0, None

        good = status.flatten() == 1
        if not np.any(good):
            return None, 0, None

        new_pts = p1.reshape(-1, 2)[good]
        old_pts = p0.reshape(-1, 2)[good]
        
        if len(new_pts) < MIN_FEATURES:
            return None, 0, None

        # –û—Ü–µ–Ω–∫–∞ –∞—Ñ—Ñ–∏–Ω–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        M, mask = cv2.estimateAffinePartial2D(old_pts, new_pts, method=cv2.RANSAC, ransacReprojThreshold=6.0)
        inliers = mask.sum() if mask is not None else 0
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∏–±—Ä–∞—Ü–∏–π)
        center = np.mean(new_pts, axis=0)
        self.history.append(center)
        if len(self.history) > self.window_size:
            self.history.pop(0)
            
        if len(self.history) == self.window_size:
            smoothed_center = np.mean(self.history, axis=0)
        else:
            smoothed_center = center
            
        return new_pts, inliers, smoothed_center

# ----------------- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ª–µ—Å–µ–Ω–∫–∏ —Å —Ü–µ–Ω—Ç—Ä–æ–º –º–∞—Å—Å —Ç–æ—á–µ–∫ -----------------
def rope_ladder_waypoint_management(waypoints, current_center, anchor_center_fixed, tracked_pts, distance_threshold=DISTANCE_THRESHOLD):
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–µ—Å—Ç–Ω–∏—Ü–µ–π —Å —Ü–µ–Ω—Ç—Ä–æ–º –º–∞—Å—Å —Ç–æ—á–µ–∫ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ waypoint.
    
    Args:
        waypoints: –°–ø–∏—Å–æ–∫ —Ç–æ—á–µ–∫ –ª–µ—Å—Ç–Ω–∏—Ü—ã
        current_center: –¢–µ–∫—É—â–∏–π –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Ü–µ–Ω—Ç—Ä
        anchor_center_fixed: –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞
        tracked_pts: –ú–∞—Å—Å–∏–≤ —Ç–µ–∫—É—â–∏—Ö —Ç—Ä–µ–∫–∞–µ–º—ã—Ö —Ç–æ—á–µ–∫
    """
    if len(waypoints) == 0:
        return waypoints

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ü–µ–Ω—Ç—Ä –º–∞—Å—Å —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞
    current_to_anchor = np.linalg.norm(current_center - anchor_center_fixed)
    last_center = waypoints[-1]['center']
    last_to_anchor = np.linalg.norm(last_center - anchor_center_fixed)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π —Å—Ç—É–ø–µ–Ω—å–∫–∏
    if current_to_anchor > last_to_anchor + BACKTRACK_MARGIN:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π waypoint —Å —Ü–µ–Ω—Ç—Ä–æ–º –º–∞—Å—Å —Ç–µ–∫—É—â–∏—Ö —Ç–æ—á–µ–∫
        new_waypoint_center = np.mean(tracked_pts, axis=0)  # –¶–µ–Ω—Ç—Ä –º–∞—Å—Å –≤—Å–µ—Ö —Ç—Ä–µ–∫–∞–µ–º—ã—Ö —Ç–æ—á–µ–∫
        
        wp = {
            'center': new_waypoint_center.copy(),
            'timestamp': time.time(),
            'cumulative': waypoints[-1]['cumulative'] + (new_waypoint_center - last_center),
            'points': tracked_pts.copy()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ –¥–ª—è –±—É–¥—É—â–∏—Ö —Ä–∞—Å—á–µ—Ç–æ–≤
        }
        waypoints.append(wp)
        logging.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Ç–æ—á–∫–∞ –ª–µ—Å—Ç–Ω–∏—Ü—ã —Å —Ü–µ–Ω—Ç—Ä–æ–º –º–∞—Å—Å {new_waypoint_center}")
    
    # –í–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—É–ø–µ–Ω—å–∫–µ
    elif len(waypoints) > 1:
        dist_to_prev = np.linalg.norm(current_center - waypoints[-2]['center'])
        if dist_to_prev < HYSTERESIS_MARGIN:
            del waypoints[-1]
            logging.info(f"üîô –í–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ç–æ—á–∫–µ (–æ—Å—Ç–∞–ª–æ—Å—å: {len(waypoints)})")
    
    return waypoints

# ----------------- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª -----------------
def main():
    logging.info("üöÄ –°—Ç–∞–±–∏–ª—å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –ª–µ—Å—Ç–Ω–∏—Ü—ã ‚Äî –∑–∞–ø—É—Å–∫")
    
    detector = FastBriskDetector(MIN_FEATURES, MAX_FEATURES)
    tracker = RobustTracker()
    kalman = EnhancedKalman2D(process_noise=1e-3, measurement_noise=1e-1)
    
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, IMAGE_WIDTH_PX)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, IMAGE_HEIGHT_PX)
    cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)
    
    waypoints = []
    anchor_center_fixed = None
    tracking_active = False
    last_update_time = 0
    dx_px, dy_px = 0.0, 0.0
    angle_deg = 0.0
    
    prev_gray = None
    tracked_pts = None
    frame_idx = 0

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                time.sleep(FRAME_INTERVAL)
                continue
                
            frame_idx += 1
            frame_roi = frame if ROI is None else frame[ROI[1]:ROI[1]+ROI[3], ROI[0]:ROI[0]+ROI[2]]
            gray = cv2.cvtColor(frame_roi, cv2.COLOR_BGR2GRAY)
            
            if not is_tracking_enabled():
                if tracking_active:
                    logging.info("üî¥ –¢—Ä–µ–∫–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                    waypoints.clear()
                    tracking_active = False
                time.sleep(FRAME_INTERVAL)
                continue
                
            if not tracking_active:
                pts = detector.detect(gray)
                if pts is not None and len(pts) >= MIN_FEATURES:
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ waypoint —Å —Ü–µ–Ω—Ç—Ä–æ–º –º–∞—Å—Å –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫
                    initial_center = np.mean(pts, axis=0)
                    waypoints = [{
                        'center': initial_center.copy(), 
                        'cumulative': np.array([0.0, 0.0]), 
                        'points': pts.copy()
                    }]
                    anchor_center_fixed = initial_center.copy()
                    tracked_pts = pts
                    prev_gray = gray.copy()
                    kalman = EnhancedKalman2D(process_noise=1e-3, measurement_noise=1e-1)
                    kalman.correct_and_predict(initial_center)
                    tracking_active = True
                    logging.info(f"üü¢ –¢—Ä–µ–∫–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω. –Ø–∫–æ—Ä—å: {anchor_center_fixed}")
                else:
                    logging.debug("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫")
                time.sleep(FRAME_INTERVAL)
                continue

            # –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–∫–∏–Ω–≥
            new_pts, inliers, smoothed_center = tracker.track(prev_gray, gray, tracked_pts)
            
            if new_pts is None or len(new_pts) < MIN_FEATURES or smoothed_center is None:
                logging.info("–ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–∞")
                new_pts = detector.detect(gray)
                if new_pts is not None and len(new_pts) >= MIN_FEATURES:
                    tracked_pts = new_pts
                    prev_gray = gray.copy()
                    continue
                else:
                    # –ü—Ä–∏ –ø–æ—Ç–µ—Ä–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ
                    if offset_buffer:
                        avg_dx = int(round(sum(x for x, y in offset_buffer) / len(offset_buffer)))
                        avg_dy = int(round(sum(y for x, y in offset_buffer) / len(offset_buffer)))
                    else:
                        avg_dx, avg_dy = 0, 0
                    save_offset(avg_dx, avg_dy, 0.0, in_meters=False)
                    continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ inliers
            min_inliers = max(MIN_INLIER_COUNT, len(new_pts) * INLIER_SAVE_RATIO)
            if inliers < min_inliers:
                logging.warning(f"–ù–∏–∑–∫–∏–µ inliers ({inliers} < {min_inliers}) -> –ø—Ä–æ–ø—É—Å–∫")
                dx_px, dy_px = 0, 0
                avg_dx, avg_dy = 0, 0
            else:
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ö–∞–ª–º–∞–Ω–æ–º
                kalmed = kalman.correct_and_predict(smoothed_center)
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ waypoints
                now = time.time()
                if now - last_update_time >= LADDER_UPDATE_INTERVAL:
                    waypoints = rope_ladder_waypoint_management(waypoints, kalmed, anchor_center_fixed, new_pts)
                    last_update_time = now
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–º–µ—â–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ waypoint
                if len(waypoints) > 0:
                    last_waypoint_center = waypoints[-1]['center']
                    offset = kalmed - last_waypoint_center
                    dx_px, dy_px = int(offset[0]), int(offset[1])
                else:
                    dx_px, dy_px = 0, 0
                
                # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –±—É—Ñ–µ—Ä
                offset_buffer.append((dx_px, dy_px))
                avg_dx = int(round(sum(x for x, y in offset_buffer) / len(offset_buffer)))
                avg_dy = int(round(sum(y for x, y in offset_buffer) / len(offset_buffer)))

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–º–µ—â–µ–Ω–∏—è
                if SAVE_IN_METERS and CURRENT_HEIGHT_M is not None:
                    dx_m, dy_m = px_to_m(avg_dx, avg_dy, CURRENT_HEIGHT_M)
                    save_offset(dx_m, dy_m, angle_deg, in_meters=True)
                else:
                    save_offset(avg_dx, avg_dy, angle_deg, in_meters=False)

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            if DEBUG:
                debug_frame = frame.copy()
                for i, wp in enumerate(waypoints):
                    center = tuple(map(int, wp['center']))
                    cv2.circle(debug_frame, center, 6, (0,255,0), -1)
                    cv2.putText(debug_frame, f"W{i}", (center[0]+5, center[1]-5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
                
                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è
                state = kalman.kf.statePost[:2].flatten()
                kalmed_int = (int(state[0]), int(state[1]))
                cv2.circle(debug_frame, kalmed_int, 8, (0,0,255), -1)
                cv2.imshow("DEBUG", debug_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            tracked_pts = new_pts
            prev_gray = gray.copy()
            time.sleep(max(0, FRAME_INTERVAL - (time.time() - now)))

    except KeyboardInterrupt:
        logging.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)
    finally:
        cap.release()
        cv2.destroyAllWindows()
        logging.info("–°–∏—Å—Ç–µ–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

if __name__ == "__main__":
    main()